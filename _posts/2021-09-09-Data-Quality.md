---
layout: post
type: blog
title: Demystifying Data Quality in Machine Learning ğŸ¤“
comments: true
mathjax: true
---

<p><strong><em>DATA is the new oil</em></strong>ğŸ›¢ï¸ As <a href="https://twitter.com/hashtag/DataCentric">#DataCentric</a> approaches to <a href="https://twitter.com/hashtag/ML">#ML</a> gather traction, access to diverse, comprehensive, and more importantly quality data has been the talk of the town. Along these lines, it's important to understand what does QUALITY really means in the context of DATA ğŸ”¢ğŸ§µğŸ‘‡ğŸ»</p>

</br>

<center>
<blockquote class="twitter-tweet"><p lang="en" dir="ltr">DATA is the new oilğŸ›¢ï¸ As <a href="https://twitter.com/hashtag/DataCentric?src=hash&amp;ref_src=twsrc%5Etfw">#DataCentric</a> approaches to <a href="https://twitter.com/hashtag/ML?src=hash&amp;ref_src=twsrc%5Etfw">#ML</a> gather traction, access to diverse, comprehensive, and more importantly quality data has been the talk of the town. Along these lines, it&#39;s important to understand what does QUALITY really means in the context of DATA ğŸ”¢ğŸ§µğŸ‘‡ğŸ»</p>&mdash; Sculpting Data: First Act of Machine Learning ğŸ“– (@DataForML) <a href="https://twitter.com/DataForML/status/1436215505782673421?ref_src=twsrc%5Etfw">September 10, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>

</br>

<p><strong>DATA QUALITY</strong> refers to the qualitative/quantitative state of information we possess. Factors like accuracy, completeness, consistency, reliability, and whether data is up to date can help us measure it âš–ï¸ Check out this cool illustration by <a href="https://twitter.com/GradientFlowR">@GradientFlowR</a>!</p>

</br>

<figure class="wp-block-image"><img src="https://pbs.twimg.com/media/E-50EQxVIAA--sb.jpg" alt=""/></figure>

</br>

<p>However sophisticated our <a href="https://twitter.com/hashtag/MachineLearning">#MachineLearning</a> models might be, poor quality data can never help effectively solve the problem at hand. Here are some pointers to keep a quality check on our data going forward ğŸ¤ŸğŸ»</p>

<p>The first step is to understand data, and how it solves our use case, a concept called <strong>DATA PROFILING</strong> ğŸ¥¸ It involves reviewing the source, understanding structure, summarizing data volume, side-information, other stats, etc. This step helps uncover quality issues from the get-go.</p>

<p>Data changes over time, so itâ€™s crucial to develop <strong>DATA HEALTH MEASUREMENTS</strong> to signal when quality degrades ğŸ“‰ Metrics developed along the data quality dimensions mentioned previously can be very helpful in continuous health monitoring and we can tailor them for our use cases.</p>

<p>Despite all checks, quality issues might still creep in. This is where <strong>DATA REPAIR</strong> comes into play ğŸ› ï¸ We should invest in tools that help in error diagnosis &amp; automatically apply easy fixes like deduplication, imputation, etc. while seeking manual help for advanced resolutions.</p>

<p>If you are interested in reading more about QUALITY DATA and how to build your own dataset from scratch, grab a copy of <a href="https://www.amazon.com/dp/B08RN47C5T">Sculpting DataForML</a> today and learn how to sculpt data the right way using <a href="https://twitter.com/hashtag/Python">#Python</a> and other <a href="https://twitter.com/hashtag/OpenSource">#OpenSource</a> tools!</p>

</br>
 
 <center>
  <iframe type="text/html" width="336" height="550" frameborder="0" allowfullscreen style="max-width:100%" src="https://read.amazon.com/kp/card?asin=B08RN47C5T&preview=inline&linkCode=kpe&ref_=cm_sw_r_kb_dp_SM5Z75YRJTFFDKF860QN&tag=mobile0a1329f-20" ></iframe>
 </center>
 
 </br>
 
 <p>We found the following article very insightful, it talks about the concept of DATA QUALITY and ways to combat it. Do read it if you get a chance! gradientflow.com/data-quality-unpacked</p>
 

</br>
<hr>
